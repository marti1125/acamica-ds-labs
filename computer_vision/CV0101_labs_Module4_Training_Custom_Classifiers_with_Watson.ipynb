{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai/\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Logo/SNLogo.png\" width=\"200\" align=\"center\">\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Lab - Training Custom Classifiers with IBM Watson Visual Recognition in Python</h1>\n",
    "\n",
    "<h2>Introduction</h2>\n",
    "\n",
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "-   How to operate the Watson Visual Recognition API and OpenCV using the Python Programming Language\n",
    "-   Understand the advantage of using the Watson Visual Recognition API over the Graphic User Interface on the Browser\n",
    "-   How to automate the training, and testing of your Visual Recognition model.\n",
    "\n",
    "<p>In this lab you will be training a Visual Recognition model that classify different kinds of dogs by running python code.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<font size=\"3\"><strong>Click on the links to go to the following sections:</strong></font>\n",
    "<br>\n",
    "<h2>Table of Contents</h2>\n",
    "<ol>\n",
    "    <li><a href=\"#ref1\">IBM Watson Package</a></li>\n",
    "    <li><a href=\"#ref2\">Setting the API key for IBM Watson Visual Recognition</a></li>\n",
    "    <li><a href=\"#ref3\">Training the Classifier</a></li>\n",
    "    <li><a href=\"#ref4\">Testing the Classifier</a></li>\n",
    "    <li><a href=\"#ref5\">Exercises</a></li>\n",
    "</ol>    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "\n",
    "<h2>IBM Watson Package</h2>\n",
    "In order to run this lab we need to import the following package.\n",
    "<ul>\n",
    "    <li>IBM Watson: which allows access to the Watson Visual Recognition API</li>\n",
    "</ul>\n",
    "The code below will install IBM Watson. \n",
    "\n",
    "To run, click on the code cell below and press \"shift + enter\".\n",
    "\n",
    "<b>NOTE - The Watson Developer Cloud Package has been deprecated and has been replaced by the IBM Watson Package </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: ibm-watson in c:\\users\\marti\\anaconda3\\envs\\ml\\lib\\site-packages (4.7.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in c:\\users\\marti\\anaconda3\\envs\\ml\\lib\\site-packages (from ibm-watson) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client==0.48.0 in c:\\users\\marti\\anaconda3\\envs\\ml\\lib\\site-packages (from ibm-watson) (0.48.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0,>=2.0 in c:\\users\\marti\\anaconda3\\envs\\ml\\lib\\site-packages (from ibm-watson) (2.25.0)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cloud-sdk-core==1.7.3 in c:\\users\\marti\\anaconda3\\envs\\ml\\lib\\site-packages (from ibm-watson) (1.7.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\marti\\anaconda3\\envs\\ml\\lib\\site-packages (from python-dateutil>=2.5.3->ibm-watson) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\marti\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3.0,>=2.0->ibm-watson) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in c:\\users\\marti\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3.0,>=2.0->ibm-watson) (1.26.2)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\marti\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3.0,>=2.0->ibm-watson) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\marti\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3.0,>=2.0->ibm-watson) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: PyJWT>=1.7.1 in c:\\users\\marti\\anaconda3\\envs\\ml\\lib\\site-packages (from ibm-cloud-sdk-core==1.7.3->ibm-watson) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ibm-watson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Goal of this lab:</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this lab, we will be creating a completely new image classifier using training images. We will train a custom classifier to identify between three different dog breeds (Golden Retriever, Beagle and Husky).</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Images/dog-breed.png\" width=\"480\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref2\"></a>\n",
    "\n",
    "<h2>Setting the API key for IBM Watson Visual Recognition</h2>\n",
    "\n",
    "<p>In order for you to use the IBM Watson Visual Recognition API, you will need the API key of the Visual Recognition instance that you have created in the previous sections.</p>\n",
    "\n",
    "<p>Log into your IBM Cloud Account with the following link.</p> <a href=\"https://cocl.us/CV0101EN_IBM_Cloud_Login\">https://cloud.ibm.com</a>\n",
    "<ol>\n",
    "    <li>Click on <b>Services</b></li>\n",
    "    <li>Under Services, click on your Watson Visual Recognition Instance</li>\n",
    "    <li>Copy the <b>API Key</b> and past it in the code cell below</li>\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Images/API_Key.png\" width=\"680\">\n",
    "    <li>Then press \"ctrl + enter\" to run the code cell.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste your API key for IBM Watson Visual Recognition below:\n",
    "my_apikey = 'xxxxxxxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Initialize Watson Visual Recognition</h4>\n",
    "Lets create your own Watson Visual Recognition instance, it will allow you to make calls to the Watson Visual Recognition API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import VisualRecognitionV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "authenticator = IAMAuthenticator(my_apikey)\n",
    "\n",
    "visrec = VisualRecognitionV3('2018-03-19', \n",
    "                             authenticator=authenticator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We are going to train an Image Recognition model to classify different types of dog. The dataset that we are going to use are the zip files that we use below</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>beagle.zip</li>\n",
    "    <li>husky.zip</li>\n",
    "    <li>golden-retriever.zip</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref3\"></a>\n",
    "\n",
    "<h2>Training Classifier</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Download the differerent breed of dog images as zip files</h4>\n",
    "<p>We will use the <b>urlretrieve</b> method from the <b>urllib.request</b> library to download the dataset above.</p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('goldenretriever.zip', <http.client.HTTPMessage at 0x1dbdcaacf10>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Downloading Beagle dataset\n",
    "urllib.request.urlretrieve(\"http://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/Beagle.zip\", \n",
    "                           \"beagle.zip\")\n",
    "\n",
    "# Downloading Husky dataset\n",
    "urllib.request.urlretrieve(\"http://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/Husky.zip\", \n",
    "                           \"husky.zip\")\n",
    "\n",
    "# Downloading Golden Retriever dataset\n",
    "urllib.request.urlretrieve(\"http://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/GoldenRetriever.zip\", \n",
    "                           \"goldenretriever.zip\") #note that we should remove any hyphens from the zip file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Lets train our Visual Recognition model to recognize the three breeds of dogs using the <b>create_classifier</b> method from the Watson Image Recognition API.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "    pass\n",
    "else:\n",
    "    # Handle target environment that doesn't support HTTPS verification\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:<HTML><HEAD>\n",
      "<TITLE>Internal Server Error</TITLE>\n",
      "</HEAD><BODY>\n",
      "<H1>Internal Server Error - Write</H1>\n",
      "The server encountered an internal error or misconfiguration and was unable to\n",
      "complete your request.<P>\n",
      "Reference&#32;&#35;4&#46;e7f1cb8&#46;1605997350&#46;2db9122f\n",
      "</BODY></HTML>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marti\\anaconda3\\envs\\ml\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\", line 224, in send\n",
      "    raise ApiException(\n",
      "ibm_cloud_sdk_core.api_exception.ApiException: Error: <HTML><HEAD>\n",
      "<TITLE>Internal Server Error</TITLE>\n",
      "</HEAD><BODY>\n",
      "<H1>Internal Server Error - Write</H1>\n",
      "The server encountered an internal error or misconfiguration and was unable to\n",
      "complete your request.<P>\n",
      "Reference&#32;&#35;4&#46;e7f1cb8&#46;1605997350&#46;2db9122f\n",
      "</BODY></HTML>\n",
      ", Code: 503\n"
     ]
    },
    {
     "ename": "ApiException",
     "evalue": "Error: <HTML><HEAD>\n<TITLE>Internal Server Error</TITLE>\n</HEAD><BODY>\n<H1>Internal Server Error - Write</H1>\nThe server encountered an internal error or misconfiguration and was unable to\ncomplete your request.<P>\nReference&#32;&#35;4&#46;e7f1cb8&#46;1605997350&#46;2db9122f\n</BODY></HTML>\n, Code: 503",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mApiException\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-681607174489>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m      \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'goldenretriever.zip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgretriever\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m      \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'husky.zip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhusky\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         response = visrec.create_classifier(name=\"dogbreedclassifier\",\n\u001b[0m\u001b[0;32m      6\u001b[0m                                         positive_examples={'beagle': beagle, \\\n\u001b[0;32m      7\u001b[0m                                                            \u001b[1;34m'goldenretriever'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgretriever\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\ibm_watson\\visual_recognition_v3.py\u001b[0m in \u001b[0;36mcreate_classifier\u001b[1;34m(self, name, positive_examples, negative_examples, negative_examples_filename, **kwargs)\u001b[0m\n\u001b[0;32m    278\u001b[0m                                        files=form_data)\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\ibm_cloud_sdk_core\\base_service.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m                                         response.status_code)\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m             raise ApiException(\n\u001b[0m\u001b[0;32m    225\u001b[0m                 response.status_code, http_response=response)\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mApiException\u001b[0m: Error: <HTML><HEAD>\n<TITLE>Internal Server Error</TITLE>\n</HEAD><BODY>\n<H1>Internal Server Error - Write</H1>\nThe server encountered an internal error or misconfiguration and was unable to\ncomplete your request.<P>\nReference&#32;&#35;4&#46;e7f1cb8&#46;1605997350&#46;2db9122f\n</BODY></HTML>\n, Code: 503"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('beagle.zip', 'rb') as beagle, \\\n",
    "     open('goldenretriever.zip', 'rb') as gretriever, \\\n",
    "     open('husky.zip', 'rb') as husky:\n",
    "        response = visrec.create_classifier(name=\"dogbreedclassifier\",\n",
    "                                        positive_examples={'beagle': beagle, \\\n",
    "                                                           'goldenretriever': gretriever, \\\n",
    "                                                           'husky': husky})\n",
    "print(json.dumps(response.get_result(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f661ca2e0b3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#lets grab the classifier id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"classifier_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclassifier_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "#lets grab the classifier id\n",
    "classifier_id = response.get_result()[\"classifier_id\"]\n",
    "classifier_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2\">\n",
    "    <h2>Note!</h2> \n",
    "    <p>If you receive the following error.</p>\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Images/Error-Code.png\" width=\"1080\">\n",
    "    <p>It means that you have more than 1 Visual Recognition Instances running on your lite plan, and the lite plan only allows for no more than 2 Visual Recognition instances. So you might want to delete one of your custom classifier in your Watson Visual Recognition Instance.</p>\n",
    "        <p>Log into your IBM Cloud Account with the following link.</p> <p><a href=\"https://cocl.us/CV0101EN_IBM_Cloud_Login\">https://cloud.ibm.com</a></p>\n",
    "    <ol>\n",
    "        <li>Click on <b>Services</b></li>\n",
    "        <li>Under Services, click on your Watson Visual Recognition Instance</li>\n",
    "        <li>Then click on Create a Custom Model</li>\n",
    "        <li>Then delete one of your Custom Visual Recognition Model</li>\n",
    "    </ol>\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Images/Delete-Instance.png\" width=\"680\">\n",
    "</div>\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Is the model still training?</h4>\n",
    "Depending on the number of images, it may take <b>a Several Minutes </b> for Watson to build a custom classifier. Please wait tell you get <b> Good to Go<b> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7ba76319d12e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mStatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvisrec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'status'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mStatus\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Please, Wait to complete training.......\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Good to go \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classifier_id' is not defined"
     ]
    }
   ],
   "source": [
    "Status = visrec.get_classifier(classifier_id=classifier_id, verbose=True).get_result()['status']\n",
    "if Status=='training': \n",
    "    print (\"Please, Wait to complete training.......\")\n",
    "else:\n",
    "    print(\"Good to go \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>List all (custom) classifiers</h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>If the status is still training, please rerun the above cell and wait until you see ready</h4> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visrec.list_classifiers(verbose=True).get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref4\"></a>\n",
    "\n",
    "<h2>Testing Classifier</h2>\n",
    "<p>Let's test the classifier, the function <b>getdf_visrec</b> below uses the method <b>classify</b> from Watson Visual Recognition API to upload the image to the classifier and give us a result in JSON(JavaScript Object Notation) format. Then we use the method <b>json_normalize</b> from the \"Pandas\" library in Python to turn the result into a table because it is more human readable.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "\n",
    "def getdf_visrec(url, classifier_ids, apikey = my_apikey):\n",
    "    \n",
    "    json_result = visrec.classify(url=url,\n",
    "                              threshold='0.6',\n",
    "                              classifier_ids=classifier_id).get_result()\n",
    "    \n",
    "    json_classes = json_result['images'][0]['classifiers'][0]['classes']\n",
    "    \n",
    "    df = json_normalize(json_classes).sort_values('score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/GoldenRetriever1_stacked.jpg\">\n",
    "<p>Let's test our Visual Recognition model on this picture of Golden Retriever</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Please wait for your Custom Model to finish training before you upload your test image to your Custom Classifier, <b>you might get an error if your model is still training and you run the function below.</p>\n",
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Images/Training.png\" width=\"680\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getdf_visrec(url = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/GoldenRetriever1_stacked.jpg',\n",
    "            classifier_ids=classifier_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/cat-2083492_960_720.jpg\">\n",
    "<p>Lets test our Visual Recognition model on this picture of cat</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getdf_visrec(url = 'http://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/cat-2083492_960_720.jpg',\n",
    "            classifier_ids=classifier_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Our model will mis-classify the cat in the picture because our custom visual recognition model is only trained for recognizing different breeds of dogs.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Delete all classifiers</h4>\n",
    "<p>If you want to delete you classifiers, lets get the classifier id tht you want to delete. The method <b>list_classifiers</b> from Watson Visual Recognition API list all the classifier in your IBM Cloud account.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "classifiers = visrec.list_classifiers(verbose=True).get_result()['classifiers']\n",
    "print(json.dumps(classifiers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just paste your classifier id and it will be deleted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycid = '' #the classifier id you want to delete\n",
    "visrec.delete_classifier(classifier_id = mycid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref5\"></a>\n",
    "\n",
    "<h2>Exercises</h2>\n",
    "<p>For the following exercises you are going to train a Custom Visual Recognition Classifier to recognize fast food items, in particular it will be able to classify food items into <b>Burger</b>, <b>Fries</b> or <b>Coke</b>.<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Question 1: Optional</h3>\n",
    "<p>After training your custom classifier, you might want to delete all the custom classifiers from your account, write a piece of code to use the *list_classifier* and *delete_classifier* method to delete all the custom classifiers in your account.</p>\n",
    "\n",
    "<p><b>Note!</b> This question is optional, if there is a classifier that you have trained and do not want to delete, skip this question.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <font color=\"red\"><b><u>here</b></u></font> for the solution.\n",
    "\n",
    "<!-- The answer is below:\n",
    "\n",
    "# The code below will delete all classifiers in your account\n",
    "for i in visrec.list_classifiers().get_result()['classifiers']:\n",
    "    print('Deleting ...' + i['classifier_id'])\n",
    "    visrec.delete_classifier(classifier_id=i['classifier_id'])\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Question 2</h3>\n",
    "<p>The link to the data set for Burger, Fries and Coke is given below</p> \n",
    "    \n",
    "<p>We will use the <b>urlretrieve</b> method from the <b>urllib.request</b> library to download the dataset below.</p> \n",
    "\n",
    "<ul>\n",
    "    <li>https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/Burger.zip</li>\n",
    "    <li>https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/Fries.zip</li>\n",
    "    <li>https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/Pizza.zip</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <font color=\"red\"><b><u>here</b></u></font> for the solution.\n",
    "\n",
    "<!-- The answer is below:\n",
    "import urllib.request\n",
    "\n",
    "#Downloading Burger dataset\n",
    "urllib.request.urlretrieve(\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/Burger.zip\", \n",
    "                           \"burger.zip\")\n",
    "\n",
    "#Downloading Fries dataset\n",
    "urllib.request.urlretrieve(\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/Fries.zip\", \n",
    "                           \"fries.zip\")\n",
    "\n",
    "#Downloading Pizza dataset\n",
    "urllib.request.urlretrieve(\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Dataset/Pizza.zip\", \n",
    "                           \"pizza.zip\")\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Question 3.1</h3>\n",
    "<p>Now we have the dataset, use the <b>create_classifier</b> method to create your fast food classifier.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <font color=\"red\"><b><u>here</b></u></font> for the solution.\n",
    "\n",
    "<!-- The answer is below:\n",
    "my_apikey = '<paste your api key here>'\n",
    "\n",
    "from ibm_watson import VisualRecognitionV3\n",
    "\n",
    "visrec_fast_food = VisualRecognitionV3(version = '2019-01-01', \n",
    "                             iam_apikey = my_apikey)\n",
    "\n",
    "import json\n",
    "with open('burger.zip', 'rb') as burger, \\\n",
    "     open('fries.zip', 'rb') as fries, \\\n",
    "     open('pizza.zip', 'rb') as pizza:\n",
    "    new_response = visrec_fast_food.create_classifier(name=\"fastfoodclassifier\",\n",
    "                                        positive_examples={'burger': burger, \\\n",
    "                                                           'fries': fries, \\\n",
    "                                                           'pizza': pizza})\n",
    "\n",
    "    print(json.dumps(new_response.get_result(), indent=2))\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Question 3.2</h3>\n",
    "<p>Since we will need the classifier_id, grab the classifier_id from the response of create_classifier and store it into a variable.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n",
    "#lets grab the classifier id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <font color=\"red\"><b><u>here</b></u></font> for the solution.\n",
    "\n",
    "<!-- The answer is below:\n",
    "#lets grab the classifier id\n",
    "fast_food_classifier_id = new_response.get_result()['classifier_id']\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Question 4</h3>\n",
    "<p>Get a url of a picture of fast food and use the <b>getdf_visrec</b> function to classify the picture. <b>Before that, please make sure that your model is trained and ready </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to check if your model is ready to go \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <font color=\"red\"><b><u>here</b></u></font> for the solution.\n",
    "\n",
    "<!-- The answer is below:\n",
    "gStatus = visrec.get_classifier(classifier_id=fast_food_classifier_id, verbose=True).get_result()['status']\n",
    "if Status=='training': \n",
    "    print (\"Please, Wait to complete training.......\")\n",
    "else:\n",
    "    print(\"Good to go \")\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <font color=\"red\"><b><u>here</b></u></font> for the solution.\n",
    "\n",
    "<!-- The answer is below:\n",
    "getdf_visrec(url = 'fast_food_image_url',\n",
    "            classifier_ids=fast_food_classifier_id)\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Thank you for completing this notebook</h1>\n",
    "You can read more about Watson Visual Recognition APIs from the following link.\n",
    "<a href=\"https://cloud.ibm.com/apidocs/visual-recognition?code=python\">https://cloud.ibm.com/apidocs/visual-recognition</a>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<h2>Get IBM Watson Studio free of charge!</h2>\n",
    "    <p><a href=\"https://cloud.ibm.com/catalog/services/watson-studio\"><img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/CV0101/Logo/BottomAd.png\" width=\"750\" align=\"center\"></a></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/yi-leng-yao-84451275/\" target=\"_blank\" >Yi Yao</a>\n",
    "\n",
    "## Other Contributors\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/nayefaboutayoun/\" target=\"_blank\">Nayef Abou Tayoun</a> \n",
    "\n",
    "## Change Log\n",
    "\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                 |\n",
    "| ----------------- | ------- | ---------- | ---------------------------------- |\n",
    "| 2020-08-27        | 2.0     | Anamika    | Moved lab to course repo in GitLab |\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
